# Aprendizaje Supervisado y Optimizadores

Cuando hablamos de aprendizaje supervisado, nos referimos al proceso en el cual le damos a una red neuronal una serie de entradas o _inputs_ para las cuales ya sabemos su clasificación o _etiqueta_, después lo que hacemos es medir el error entre la salida que nos da la red neuronal y el resultado esperado que tenemos almacenado previamente, para finalmente ajustar los pesos _weights_ de las conexiones de entrada y esperar por una mejora

## Errores

Podemos representar el error de muchas maneras, una de las más comunes es el Error Cuadrático Medio: _MSE = 1&frasl;2  (y<sub>conocida</sub> - y<sub>obtenida</sub>)<sup>2</sup>_ (para este caso en particular). Puedes ir más a fondo [aquí](https://es.wikipedia.org/wiki/Error_cuadr%C3%A1tico_medio).

Para el primer ejemplo de nuestro perceptrón, para mantenerlo simple, podemos representar el error de la siguiente forma: _err = y<sub>conocida</sub> - y<sub>obtenida</sub>_

¿Por qué? Bueno, la razón es que podemos ver todos los posibles resultados de error para este ejemplo en particular, de esta manera:

| Esperada | Obtenida | Error |
|----------|----------|-------|
| -1 | +1 | 0 |
| -1 | +1 | -2 |
| +1 | -1 | +2 |
| +1 | +1 | 0 |

## Optimizando y ajustando pesos

Principalmente, nuestra meta con el entrenamiento es optimizar estos valores (_weights_) para que nuestra salida se convierta en la esperada, podemos pensar en esto como el hecho de añadir una variación a los valores anteriores, de la siguiente manera:  _W<sub>n+1</sub> = W<sub>n</sub> + &Delta;W<sub>n</sub>_ Ahora tenemos que pensar una manera para calcular _&Delta;W<sub>n</sub>_ correspondiente a todos los pesos de las entradas del perceptrón

## Decenso en Gradiente

Para este ejemplo, usaremos una versión simplificada de este algoritmo, el cual puede encontrar mas a profundidad [aquí](https://en.wikipedia.org/wiki/Gradient_descent). El proceso principal para calcular &Delta;W<sub>n</sub> es multiplicar el error por la entrada respectiva, de esta manera la dirección de la nueva salida se moverá en dirección al error, al principio puede resultar un poco confuso, pero por simplicidad, diremos que el proceso está definido así: _&Delta;W<sub>n</sub> = err * X<sub>n</sub>_ y _err_ esta definido como: _y<sub>conocida</sub> - y<sub>obtenida</sub>_.

Aun así tenemos un problema interesante, debemos saber que tanto queremos cambiar la dirección de nuestro peso, ya que si lo hacemos demasiado rápido, existe la posibilidad de que sobreestimemos y nos pasemos de nuestra salida deseada, ahora produciendo valores equivocados pero en la otra dirección, es por eso que introducimos una nueva variable llamada _porcentaje de aprendizaje (learning rate)_ la cual controla que tanto nos movemos hacia el error, por lo tanto nuestra formula queda de la siguiente manera: _&Delta;W<sub>n</sub> = err * X<sub>n</sub>_ donde _err_ está definido como: _y<sub>conocida</sub> - y<sub>obtenida</sub>_ y _Lr &in; ]0, 1]_

[siguiente](/docs/spa/1.perceptron/3.perceptron_refinado.md)